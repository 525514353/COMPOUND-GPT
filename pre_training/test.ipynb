{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from datasets import load_dataset,load_from_disk\n",
    "# \\t is the tab character in Python\n",
    "dataset = load_from_disk(r'D:\\system\\桌面\\lcm-code\\tokenizers_lcm\\dataset')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-20T20:21:05.007818Z",
     "end_time": "2024-04-20T20:21:06.295723Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from transformers import GPT2TokenizerFast\n",
    "tokenizer=GPT2TokenizerFast.from_pretrained(r'D:\\system\\桌面\\lcm-code\\tokenizers_lcm\\tokenizer_gpt100.json')\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-20T20:21:07.870232Z",
     "end_time": "2024-04-20T20:21:09.909686Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-20T20:21:10.409365Z",
     "end_time": "2024-04-20T20:21:11.053656Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def tokenize(element):\n",
    "    outputs = tokenizer(\n",
    "        element[\"isosmiles\"],\n",
    "    )\n",
    "    return outputs\n",
    "\n",
    "\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize, batched=True,remove_columns=dataset['train'].column_names\n",
    ")\n",
    "\n",
    "length=[len(i) for i in tokenized_dataset['train']['input_ids']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-20T20:21:12.108157Z",
     "end_time": "2024-04-20T20:21:14.898156Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask'],\n        num_rows: 213530\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask'],\n        num_rows: 26692\n    })\n    val: Dataset({\n        features: ['input_ids', 'attention_mask'],\n        num_rows: 26690\n    })\n})"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset=tokenized_dataset.filter(lambda example:len(example['input_ids'])<500)\n",
    "tokenized_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-20T20:21:17.802290Z",
     "end_time": "2024-04-20T20:21:17.831805Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "import torch\n",
    "\n",
    "def keytoken_weighted_loss(inputs, logits,attention_mask):\n",
    "    # Shift so that tokens < n predict n\n",
    "    shift_labels = inputs[..., 1:]\n",
    "    shift_logits = logits[..., :-1, :]\n",
    "    # Calculate per-token loss\n",
    "    loss_fct = CrossEntropyLoss(reduction='none')\n",
    "    loss = loss_fct(shift_logits.reshape(-1, shift_logits.size(-1)), shift_labels.reshape(-1))\n",
    "    loss *= attention_mask[:,1:].reshape(-1)\n",
    "    loss = loss.mean()\n",
    "\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-20T20:21:55.556868Z",
     "end_time": "2024-04-20T20:21:55.576928Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([20, 66])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "tokenized_dataset.set_format(\"torch\")\n",
    "train_dataloader = DataLoader(tokenized_dataset[\"train\"], batch_size=20, shuffle=True,collate_fn=data_collator)\n",
    "eval_dataloader = DataLoader(tokenized_dataset[\"val\"], batch_size=20,collate_fn=data_collator)\n",
    "test_dataloader = DataLoader(tokenized_dataset[\"test\"], batch_size=20,collate_fn=data_collator)\n",
    "for batch in train_dataloader:\n",
    "    break\n",
    "batch['input_ids'].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-20T20:22:03.593220Z",
     "end_time": "2024-04-20T20:22:03.617943Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def evaluate_improve(dataloader):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        with torch.no_grad():\n",
    "            logits=model(batch['input_ids']).logits\n",
    "            loss=keytoken_weighted_loss(batch['input_ids'],logits,batch['attention_mask'])\n",
    "\n",
    "        losses.append(loss.unsqueeze(dim=0))\n",
    "    loss = torch.mean(torch.cat(losses,dim=0))\n",
    "    try:\n",
    "        perplexity = torch.exp(loss)\n",
    "    except OverflowError:\n",
    "        perplexity = float(\"inf\")\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss.item(), perplexity.item()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-20T20:22:05.880183Z",
     "end_time": "2024-04-20T20:22:05.911622Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "def precise(dataloader):\n",
    "    model.eval()\n",
    "    corrects=0\n",
    "    totals=0\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(batch[\"input_ids\"]).logits[..., :-1, :]\n",
    "\n",
    "            labels=batch[\"input_ids\"][..., 1:][batch['attention_mask'][:,1:].bool()].flatten()\n",
    "\n",
    "            predict=outputs.argmax(dim=2)[batch['attention_mask'][:,1:].bool()].flatten()\n",
    "\n",
    "            correct=(labels==predict).sum()\n",
    "            total=len(labels)\n",
    "        corrects+=correct\n",
    "        totals+=total\n",
    "    return corrects/totals"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-20T21:07:52.117474Z",
     "end_time": "2024-04-20T21:07:52.124515Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, GPT2LMHeadModel, AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    vocab_size=len(tokenizer),\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "# model = GPT2LMHeadModel(config).cuda()\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('chem_gpt100')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-20T20:22:08.417613Z",
     "end_time": "2024-04-20T20:22:12.581834Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "Accelerator.mixed_precision == 'fp16'\n",
    "accelerator = Accelerator()\n",
    "\n",
    "model, train_dataloader, eval_dataloader, test_dataloader = accelerator.prepare(\n",
    "    model, train_dataloader, eval_dataloader,test_dataloader\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-20T20:27:04.104007Z",
     "end_time": "2024-04-20T20:27:04.123950Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-20T20:22:27.070624Z",
     "end_time": "2024-04-20T20:22:58.786542Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "input=tokenizer('C1=CN(C(=O)NC1=O)C2C(C(C(O2)COP(=O)(O)OP(=O)(O)OC3C(C(C(C(O3)C(=O)O)O)O)O)O)O')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-20T20:44:55.288264Z",
     "end_time": "2024-04-20T20:44:55.319891Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([22,  9, 18, 90,  2, 22, 69, 33,  3, 79,  9, 18, 33,  3, 22, 10, 22,  2,\n        22,  2, 22,  2, 33, 10,  3, 81, 69, 33, 74, 33,  3, 33, 34, 69, 33, 74,\n        33,  3, 71, 11, 22,  2, 22,  2, 22,  2, 22,  2, 33, 11,  3, 22, 69, 33,\n         3, 33,  3, 33,  3, 33,  3, 33,  3, 33,  3, 33], device='cuda:0')"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_id=torch.tensor(input['input_ids']).cuda()\n",
    "input_id"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-20T20:44:56.692461Z",
     "end_time": "2024-04-20T20:44:56.702973Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "predict=model(input_id).logits.argmax(dim=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-20T20:44:58.432018Z",
     "end_time": "2024-04-20T20:44:58.453034Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(60, device='cuda:0')"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predict[:-1]==input_id[1:]).sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-20T20:44:59.602398Z",
     "end_time": "2024-04-20T20:44:59.619414Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.8515, device='cuda:0')"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precise(eval_dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-20T21:08:40.756368Z",
     "end_time": "2024-04-20T21:09:12.329737Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
